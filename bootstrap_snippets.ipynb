{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sunshine = 2,0\n",
    "c1=0\n",
    "c2=3\n",
    "c3=4\n",
    "LNB1=LONB[:,c1][LONB[:,c1]!=0]\n",
    "LTB1=LATB[:,c1][LATB[:,c1]!=0]\n",
    "CDB1=CODB[:,c1][CODB[:,c1]!=0]\n",
    "ATB1=ALTB[:,c1][ALTB[:,c1]!=0]\n",
    "print [LNB1.size,LTB1.size,CDB1.size,ATB1.size]\n",
    "LNB2=LONB[:,c2][LONB[:,c2]!=0]\n",
    "LTB2=LATB[:,c2][LATB[:,c2]!=0]\n",
    "CDB2=CODB[:,c2][CODB[:,c2]!=0]\n",
    "ATB2=ALTB[:,c2][ALTB[:,c2]!=0]\n",
    "print [LNB2.size,LTB2.size,CDB2.size,ATB2.size]\n",
    "# precip = 0,1\n",
    "c1=0\n",
    "c2=1\n",
    "LNL1=LONL[:,c1][LONL[:,c1]!=0]\n",
    "LTL1=LATL[:,c1][LATL[:,c1]!=0]\n",
    "CDL1=CODL[:,c1][CODL[:,c1]!=0]\n",
    "ATL1=ALTL[:,c1][ALTL[:,c1]!=0]\n",
    "print [LNL1.size,LTL1.size,CDL1.size,ATL1.size]\n",
    "LNL2=LONL[:,c2][LONL[:,c2]!=0]\n",
    "LTL2=LATL[:,c2][LATL[:,c2]!=0]\n",
    "CDL2=CODL[:,c2][CODL[:,c2]!=0]\n",
    "ATL2=ALTL[:,c2][ALTL[:,c2]!=0]\n",
    "print [LNL2.size,LTL2.size,CDL2.size,ATL2.size]\n",
    "# rainy days: 2,0\n",
    "c1=2\n",
    "c2=0\n",
    "LND1=LOND[:,c1][LOND[:,c1]!=0]\n",
    "LTD1=LATD[:,c1][LATD[:,c1]!=0]\n",
    "CDD1=CODD[:,c1][CODD[:,c1]!=0]\n",
    "ATD1=ALTD[:,c1][ALTD[:,c1]!=0]\n",
    "print [LND1.size,LTD1.size,CDD1.size,ATD1.size]\n",
    "LND2=LOND[:,c2][LOND[:,c2]!=0]\n",
    "LTD2=LATD[:,c2][LATD[:,c2]!=0]\n",
    "CDD2=CODD[:,c2][CODD[:,c2]!=0]\n",
    "ATD2=ALTD[:,c2][ALTD[:,c2]!=0]\n",
    "print [LND2.size,LTD2.size,CDD2.size,ATD2.size]\n",
    "# humidity 1,3 (might be the opposite?)\n",
    "c1=1\n",
    "c2=3\n",
    "LNH1=LONH[:,c1][LONH[:,c1]!=0]\n",
    "LTH1=LATH[:,c1][LATH[:,c1]!=0]\n",
    "CDH1=CODH[:,c1][CODH[:,c1]!=0]\n",
    "ATH1=ALTH[:,c1][ALTH[:,c1]!=0]\n",
    "print [LNH1.size,LTH1.size,CDH1.size,ATH1.size]\n",
    "LNH2=LONH[:,c2][LONH[:,c2]!=0]\n",
    "LTH2=LATH[:,c2][LATH[:,c2]!=0]\n",
    "CDH2=CODH[:,c2][CODH[:,c2]!=0]\n",
    "ATH2=ALTH[:,c2][ALTH[:,c2]!=0]\n",
    "print [LNH2.size,LTH2.size,CDH2.size,ATH2.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mcsel(big,small):\n",
    "    MC=np.zeros(big)\n",
    "    for i in range(big):\n",
    "        MC[i]=np.random.random()<small*1./big\n",
    "    return MC.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stackear D y L y hacer el MC sobre esos\n",
    "MCclp=np.empty((0))\n",
    "MClnp=np.empty((0))\n",
    "MCltp=np.empty((0))\n",
    "MCatp=np.empty((0))\n",
    "iterations=10000\n",
    "for i in range(iterations):\n",
    "    DMC=mcsel(LND1.size,LNB1.size)\n",
    "    HMC=mcsel(LNH1.size,LNB1.size)\n",
    "    LMC=mcsel(LNL1.size,LNB1.size)\n",
    "    LNMC=np.hstack((LNB1,LND1[DMC],LNH1[HMC],LNL1[LMC]))\n",
    "    LTMC=np.hstack((LTB1,LTD1[DMC],LTH1[HMC],LTL1[LMC]))\n",
    "    ATMC=np.hstack((ATB1,ATD1[DMC],ATH1[HMC],ATL1[LMC]))\n",
    "    CDMC=np.hstack((CDB1,CDD1[DMC],CDH1[HMC],CDL1[LMC]))\n",
    "    MCdata=np.vstack((LNMC,LTMC,ATMC)).T\n",
    "    kcomp=2\n",
    "    kik=0\n",
    "    kikp=1\n",
    "    gmm = GMM(kcomp, covariance_type='full', random_state=0)\n",
    "    gmm.fit(MCdata)\n",
    "    cluster_label = gmm.predict(MCdata)\n",
    "    MCcl=np.append(MCcl,CDMC[cluster_label==kik])\n",
    "    MCln=np.append(MCln,LNMC[cluster_label==kik])\n",
    "    MClt=np.append(MClt,LTMC[cluster_label==kik])    \n",
    "    MCat=np.append(MCat,ATMC[cluster_label==kik])\n",
    "    MCclp=np.append(MCclp,CDMC[cluster_label==kikp])\n",
    "    MClnp=np.append(MClnp,LNMC[cluster_label==kikp])\n",
    "    MCltp=np.append(MCltp,LTMC[cluster_label==kikp])    \n",
    "    MCatp=np.append(MCatp,ATMC[cluster_label==kikp])\n",
    "   \n",
    "np.savetxt('mcresults.txt',np.c_[MCcl,MCln,MClt,MCat])\n",
    "np.savetxt('mcresultsp.txt',np.c_[MCclp,MClnp,MCltp,MCatp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat mcresults.txt | sort -n | uniq -c | sort -nr > mcrescount.txt\n",
    "cat mcresultsp.txt | sort -n | uniq -c | sort -nr > mcrescountp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A=np.loadtxt('mcrescount.txt')\n",
    "FILTER=A[:,0]>800\n",
    "plt.scatter(-A[:, 2][FILTER], -A[:, 3][FILTER], c=A[:,0][FILTER])\n",
    "plt.colorbar()\n",
    "plt.xlim(-85,-65)\n",
    "plt.ylim(-5,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A=np.loadtxt('mcrescountp.txt')\n",
    "FILTER=A[:,0]>1000\n",
    "plt.scatter(-A[:, 2][FILTER], -A[:, 3][FILTER], c=A[:,0][FILTER])\n",
    "plt.colorbar()\n",
    "plt.xlim(-85,-65)\n",
    "plt.ylim(-5,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genprob(paux3,paux4):\n",
    "    p3=1./4\n",
    "    p4=1./16\n",
    "    p33=p3*paux3\n",
    "    p34=p4*paux4\n",
    "    lott=np.random.random(1)\n",
    "    if(lott<(p33+p34)):\n",
    "        if(lott<p33):\n",
    "            return 3\n",
    "        elif(p33<=lott<p33+p34):\n",
    "            return 4\n",
    "    else:\n",
    "         return 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseprob(i,j):\n",
    "    if((i==4.)&(j==0.)):\n",
    "        return genprob(0.,1.)\n",
    "    if((i==3.)&(j==0.)):\n",
    "        return genprob(1.,0.)\n",
    "    if((i==3.)&(j==1.)):\n",
    "        return genprob(4./5,1./5)\n",
    "    if((i==2.)&(j==1.)):\n",
    "        return genprob(4./10,0.)\n",
    "    if((i==2.)&(j==2.)):\n",
    "        return genprob(4./11,1./11)\n",
    "    if((i==1.)&(j==2.)):\n",
    "        return genprob(4./14,0.)\n",
    "    if((i==1.)&(j==3.)):\n",
    "        return genprob(4./15,1./15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Contamos cuantas variables fueron medidas por estacion, se almacena en tomados (cuyo indice coincide con el indice de listam)\n",
    "listam=np.loadtxt('listam.txt')\n",
    "df=pd.read_csv('lluvia.csv')\n",
    "tomados=np.zeros((len(listam[:,1]),4))\n",
    "for i in range(len(listam[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam[i,1]==df.CODIGO[k]):\n",
    "            tomados[i,0]+=1\n",
    "df=pd.read_csv('diaslluvia.csv')\n",
    "for i in range(len(listam[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam[i,1]==df.CODIGO[k]):\n",
    "            tomados[i,1]+=1  \n",
    "df=pd.read_csv('humedad.csv')\n",
    "for i in range(len(listam[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam[i,1]==df.CODIGO[k]):\n",
    "            tomados[i,2]+=1\n",
    "df=pd.read_csv('brillo.csv')\n",
    "for i in range(len(listam[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam[i,1]==df.CODIGO[k]):\n",
    "            tomados[i,3]+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tomados==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tomados[:,0]*336./2046)*(tomados[:,1]*336./445)*(tomados[:,2]*336./2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LLUVIA=tomados[:,0]+tomados[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HUBR=tomados[:,2]+tomados[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.,  0.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomados[LLUVIA==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  0.,  1.],\n",
       "       [ 1.,  1.,  0.,  1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomados[(tomados[:,2]==0)*(tomados[:,3]==1)*(LLUVIA==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  3.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listam[(tomados[:,2]==0)*(tomados[:,3]==1)*(LLUVIA==2),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomados[(LLUVIA[LLUVIA==2]+BRHUM[LLUVIA==2])==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((tomados[:,2]==1)*(tomados[:,1]==1)*(tomados[:,3]==1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16422287,  0.75505618,  0.16783217,  1.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptom=336./np.array([2046.,445.,2002.,336.])\n",
    "ptom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pmed=np.zeros(len(listam[:,1]))\n",
    "for i in range(len(listam[:,1])):\n",
    "    pmed[i]=1.\n",
    "    for k in range(4):\n",
    "        if(tomados[i,k]==1.):\n",
    "            pmed[i]=pmed[i]*ptom[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomados[np.argmax(pmed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.32440476,  5.95833333,  7.89124504])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pmed/pmed.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 123.,  377.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    2.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    8.]),\n",
       " array([ 1.        ,  1.22970817,  1.45941634,  1.6891245 ,  1.91883267,\n",
       "         2.14854084,  2.37824901,  2.60795718,  2.83766534,  3.06737351,\n",
       "         3.29708168,  3.52678985,  3.75649802,  3.98620618,  4.21591435,\n",
       "         4.44562252,  4.67533069,  4.90503886,  5.13474702,  5.36445519,\n",
       "         5.59416336,  5.82387153,  6.0535797 ,  6.28328786,  6.51299603,\n",
       "         6.7427042 ,  6.97241237,  7.20212054,  7.4318287 ,  7.66153687,\n",
       "         7.89124504]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28438ab350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pmed/pmed.min(), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  1.        ,  1.32440476,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.        ,  1.32440476,  1.32440476,  1.32440476,  1.        ,\n",
       "        1.32440476,  1.        ,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.        ,\n",
       "        1.32440476,  1.        ,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  7.89124504,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.        ,  1.32440476,\n",
       "        1.32440476,  1.        ,  1.32440476,  1.        ,  1.        ,\n",
       "        1.32440476,  1.        ,  1.        ,  1.        ,  1.32440476,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.        ,  1.32440476,  1.32440476,  1.        ,  1.32440476,\n",
       "        1.32440476,  1.        ,  1.32440476,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  7.89124504,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.        ,  1.        ,  1.32440476,  1.32440476,\n",
       "        7.89124504,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  7.89124504,  1.        ,  1.        ,  1.32440476,\n",
       "        7.89124504,  1.        ,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.        ,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.        ,  1.        ,\n",
       "        1.32440476,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.        ,  1.        ,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.        ,  1.        ,  1.32440476,  1.        ,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.        ,  1.        ,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.32440476,  1.        ,  1.        ,\n",
       "        7.89124504,  1.        ,  1.        ,  1.        ,  1.32440476,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.        ,  1.        ,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  7.89124504,  1.32440476,\n",
       "        1.        ,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.        ,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        5.95833333,  1.32440476,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.32440476,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.32440476,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.        ,  1.32440476,  1.        ,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.        ,\n",
       "        1.        ,  1.        ,  1.32440476,  1.        ,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        7.89124504,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.        ,  1.        ,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.        ,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.        ,  1.        ,  1.        ,  1.32440476,  1.        ,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.        ,\n",
       "        1.        ,  1.        ,  1.32440476,  1.32440476,  1.        ,\n",
       "        1.        ,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.        ,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.        ,  1.        ,\n",
       "        1.        ,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.        ,  1.        ,\n",
       "        1.        ,  5.95833333,  1.        ,  1.        ,  1.32440476,\n",
       "        1.32440476,  1.32440476,  1.32440476,  1.32440476,  1.        ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmed/pmed.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ahora seleccionamos los que cumplen al menos 1 de 3 criterios: humedad, lluvia, y dias con lluvia\n",
    "DAT3C=np.vstack((DATH,DATL,DATD))\n",
    "np.savetxt('datos3c.txt',DAT3C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "awk '{print $0}' datos3c.txt | sort -n | uniq -c > listam3c.txt\n",
    "rm datos3c.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tabla de probabilidad (peso) para 3 variables que pueden o no cumplir criterios\n",
    "def genprob3(cumple):\n",
    "    if(cumple==3.):\n",
    "        return 1./8\n",
    "    if(cumple==2.):\n",
    "        return (3./8)*(1./4)\n",
    "    if(cumple==1.):\n",
    "        return (3./8)*(1./7)\n",
    "# se multiplica la anterior tabla con la tabla de probabilidad (peso) para el criterio de brillo \n",
    "# (casos de 12-24 horas de cielos despejados)\n",
    "def parseprob3(cumple,brillo):\n",
    "    if(brillo==2.):\n",
    "        return genprob3(cumple)*3./4\n",
    "    if(brillo==1.):\n",
    "        return genprob3(cumple)*1.\n",
    "    if(brillo==0.):\n",
    "        return genprob3(cumple)*1./2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generamos una lista con las estaciones que cumplen 1 de 3 criterios, y contamos cuantos de ellos son cumplidos\n",
    "listam3c=np.loadtxt('listam3c.txt')\n",
    "# contamos cuantas variables (humedad, lluvia, y dias con lluvia) fueron medidas\n",
    "df=pd.read_csv('lluvia.csv')\n",
    "tomados3c=np.zeros(len(listam3c[:,1]))\n",
    "for i in range(len(listam3c[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam3c[i,1]==df.CODIGO[k]):\n",
    "            tomados3c[i]+=1\n",
    "df=pd.read_csv('humedad.csv')\n",
    "for i in range(len(listam3c[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam3c[i,1]==df.CODIGO[k]):\n",
    "            tomados3c[i]+=1\n",
    "df=pd.read_csv('diaslluvia.csv')\n",
    "for i in range(len(listam3c[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam3c[i,1]==df.CODIGO[k]):\n",
    "            tomados3c[i]+=1  \n",
    "# filtramos las que cumplen o pueden cumplir los 3 criterios (es decir, considerando los casos en los que no se midieron algunos de las variables)\n",
    "pfilter3c=tomados3c-listam3c[:,0]==0\n",
    "listacorta3c=listam3c[pfilter3c]\n",
    "# encontramos las estaciones en listacorta3c en las que se tomaron datos de brillo solar\n",
    "df=pd.read_csv('brillo.csv')\n",
    "tomados3cB=np.zeros(len(listacorta3c[:,1]))\n",
    "for i in range(len(listacorta3c[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listacorta3c[i,1]==df.CODIGO[k]):\n",
    "            tomados3cB[i]+=1 \n",
    "# encontramos las estaciones en listacorta3c que cumplen el criterio de brillo solar\n",
    "cbrillo3cB=np.zeros(len(listacorta3c[:,1]))\n",
    "for i in range(len(listacorta3c[:,1])):\n",
    "    for k in range(len(DATB[:,1])):\n",
    "        if(listacorta3c[i,1]==DATB[k,0]):\n",
    "            cbrillo3cB[i]+=1 \n",
    "# 0=no cumple el criterio de brillo solar, 1=si lo cumple, 2=no fue medido\n",
    "Brillo=2*(1-tomados3cB)+cbrillo3cB\n",
    "# genera un arreglo con pesos para cada estación\n",
    "probarr12=np.zeros(len(Brillo))\n",
    "for i in range(len(Brillo)):\n",
    "    probarr12[i]=parseprob3(listacorta3c[i,0],Brillo[i])\n",
    "# generación de lista expandida que incluye pesos enteros para cada estación\n",
    "lendata12=(probarr12*112*8).sum().astype(int)\n",
    "wdata12=(probarr12*112*8).astype(int)\n",
    "listaexp12=np.zeros((lendata12,5))\n",
    "kcount=0\n",
    "for i in range(len(probarr12)):        \n",
    "    for kinx in range(wdata12[i]):\n",
    "        listaexp12[kinx+kcount,:]=listacorta3c[i,:]\n",
    "    kcount=kcount+kinx+1   \n",
    "# clustering para datos sin escalar\n",
    "# clustering por mixtura gaussiana de la lista expandida, buscando un mínimo local para el criterio de información bayesiano\n",
    "# el agrupamiento se hace por lon,lat,alt\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "bicold=0\n",
    "compo=15\n",
    "BIC=np.zeros((compo+1,4))\n",
    "kik=0\n",
    "for cv_type in cv_types:\n",
    "    for kcomp in np.arange(compo)+1:        \n",
    "        gmm = GMM(kcomp, covariance_type=cv_type, random_state=0)\n",
    "        gmm.fit(listaexp12[:,2:5])\n",
    "#        if bicold<gmm.bic(listaexp12[:,2:5]):\n",
    "#        print cv_type,kcomp,gmm.bic(X_scaled[:,2:5]);\n",
    "        BIC[kcomp,kik]=gmm.bic(listaexp12[:,2:5])\n",
    "        bicold=gmm.bic(listaexp12[:,2:5])\n",
    "    kik+=1    \n",
    "# para los datos sin re-escalar, agrupamiento por mixtura gaussiana de 6 componentes\n",
    "# para kcomp=9 los importantes son 0,7 pero se mezclan mucho geográficamente\n",
    "# para kcomp=12 los importantes son 1,2,3,8 pero se mezclan mucho geográficamente \n",
    "kcomp=6\n",
    "gmm = GMM(kcomp, covariance_type='full', random_state=0)\n",
    "gmm.fit(listaexp12[:,2:5])\n",
    "cluster_label_stacked12 = gmm.predict(listaexp12[:,2:5])\n",
    "print kcomp, gmm.bic(listaexp12[:,2:5])\n",
    "# se almacenan los datos para procesarlos con bash con el fin de colapsar la lista expandida\n",
    "listastacked12=np.vstack((listaexp12.T,cluster_label_stacked12)).T\n",
    "np.savetxt('lisstck12.txt',listastacked12)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# peso estadístico para cada estación en listacorta3c\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(-listacorta3c[:,2],-listacorta3c[:,3],c=probarr12,s=100)\n",
    "plt.colorbar()\n",
    "plt.scatter(colvec[:,0],colvec[:,1],s=1)\n",
    "plt.xlim(-85,-65)\n",
    "plt.ylim(-5,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distribución de pesos est. vs. altura\n",
    "plt.scatter(probarr12,listacorta3c[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, cv_type in zip(range(4),cv_types):\n",
    "    plt.plot(np.arange(compo+1),BIC[:,i],label=cv_type)\n",
    "plt.legend()\n",
    "plt.xlim(0,15)\n",
    "plt.ylim(150000,240000)\n",
    "# mínimos locales en 6,9,12 componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "uniq -c lisstck12.txt > listcomp12.txt\n",
    "rm lisstck12.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distribución de grupos vs. altura vs. pesos estadísticos\n",
    "listcomp12=np.loadtxt('listcomp12.txt')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(listcomp12[:,6],listcomp12[:,5],c=probarr12*112*8,s=50)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probfilter=(tomados-listam[:,0]==0)\n",
    "listacorta=listam[probfilter]\n",
    "listacortacu=tomadoscu[probfilter]\n",
    "incog=4-listam[:,0][probfilter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Asize=np.hstack((AL.shape[0],AD.shape[0],AH.shape[0],AB.shape[0]))\n",
    "ptomind=Asize*1./Asize.max()\n",
    "probtom=np.ones(listacortacu.shape[0])\n",
    "for i in range(listacortacu.shape[0]):\n",
    "    for k in range(2,4):\n",
    "        if(listacortacu[i,k]==1.):\n",
    "            probtom[i]=probtom[i]*ptomind[k]\n",
    "        if(listacortacu[i,k]==0.):\n",
    "            probtom[i]=probtom[i]*(1.-ptomind[k])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "#print np.around(np.hstack((listacortacu,listacortatipo[:,np.newaxis],listacorta[:,0][:,np.newaxis])),1)\n",
    "np.set_printoptions(suppress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(-listacorta[:,2][incog==3.],-listacorta[:,3][incog==3.],c='b',s=200)\n",
    "plt.scatter(-listacorta[:,2][incog==2.],-listacorta[:,3][incog==2.],c='g',s=200)\n",
    "plt.scatter(-listacorta[:,2][incog==1.],-listacorta[:,3][incog==1.],c='y',s=200)\n",
    "plt.scatter(-listacorta[:,2][incog==0.],-listacorta[:,3][incog==0.],c='r',s=200)\n",
    "plt.scatter(colvec[:,0],colvec[:,1],s=1)\n",
    "plt.xlim(-85,-65)\n",
    "plt.ylim(-5,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genprob2(paux3,paux4):\n",
    "    p3=1./4\n",
    "    p4=1./16\n",
    "    p33=p3*paux3\n",
    "    p34=p4*paux4\n",
    "    return p33+p34  \n",
    "def parseprob3(i,j):\n",
    "    if((i==4.)&(j==0.)):\n",
    "        return genprob2(0.,1.)\n",
    "    if((i==3.)&(j==1.)):\n",
    "        return genprob2(0.,1./5)\n",
    "    if((i==2.)&(j==2.)):\n",
    "        return genprob2(0.,1./11)\n",
    "    if((i==1.)&(j==3.)):\n",
    "        return genprob2(0,1./15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probarr3=np.zeros(len(incog))\n",
    "for i in range(len(incog)):\n",
    "    probarr3[i]=parseprob3(listacorta[i,0],incog[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generamos la lista maestra con el filtro de altura > 1500 msnm\n",
    "# Sospecho que esto no es necesario\n",
    "# Aqui usamos la funcion anterior, PP le indica a la funcion cuales grupos me interesan\n",
    "altfilt=1500\n",
    "PP=[0,3,4]\n",
    "DATB=stitch(PP,ALTB,LONB,LATB,CODB,altfilt)\n",
    "PP=[1]\n",
    "DATH=stitch(PP,ALTH,LONH,LATH,CODH,altfilt)\n",
    "PP=[1,4,6,10]\n",
    "DATL=stitch(PP,ALTL,LONL,LATL,CODL,altfilt)\n",
    "PP=[0,3,5]\n",
    "DATD=stitch(PP,ALTD,LOND,LATD,CODD,altfilt)\n",
    "# Se unen todas las variables en un solo arreglo, nos quedamos con 751 datos (hay repetidos)\n",
    "# En este arreglo estan todos los datos que cumplen por lo menos uno de los criterios, y quedan a mas de 1500 msnm\n",
    "# 0=codigo, 1,2=lonlat, 3=altura (segun la funcion stitch)\n",
    "DATT=np.vstack((DATB,DATH,DATL,DATD))\n",
    "np.savetxt('datos.txt',DATT)\n",
    "# Luego unificamos con las estaciones que cumplen al menos un criterio, stdout contiene lo que comunica el proceso\n",
    "# En este caso no hay nada porque todo quedó escrito en archivo, pero no sobra verificar\n",
    "proc = subprocess.Popen([\"awk '{{print $0}}' datos.txt | sort -n | uniq -c > listam.txt\"], stdout=subprocess.PIPE, shell=True)\n",
    "proc = subprocess.Popen([\"rm datos.txt\"], stdout=subprocess.PIPE, shell=True)\n",
    "proc = subprocess.Popen([\"ls\"], stdout=subprocess.PIPE, shell=True)\n",
    "listam=np.loadtxt('listam.txt')\n",
    "stdout = proc.communicate()[0]\n",
    "stdout.replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se unen todas las variables en un solo arreglo, nos quedamos con 751 datos (hay repetidos)\n",
    "# En este arreglo estan todos los datos que cumplen por lo menos uno de los criterios, y quedan a mas de 1500 msnm\n",
    "# 0=codigo, 1,2=lonlat, 3=altura (segun la funcion stitch)\n",
    "DATT_T=np.vstack((DATBT,DATHT,DATLT,DATDT))\n",
    "np.savetxt('datostodos.txt',DATT_T)\n",
    "# Luego unificamos con las estaciones que cumplen al menos un criterio, stdout contiene lo que comunica el proceso\n",
    "# En este caso no hay nada porque todo quedó escrito en archivo, pero no sobra verificar\n",
    "proc = subprocess.Popen([\"awk '{{print $0}}' datostodos.txt | sort -n | uniq -c > listatodos.txt\"], stdout=subprocess.PIPE, shell=True)\n",
    "proc = subprocess.Popen([\"rm datostodos.txt\"], stdout=subprocess.PIPE, shell=True)\n",
    "proc = subprocess.Popen([\"ls\"], stdout=subprocess.PIPE, shell=True)\n",
    "listatodos=np.loadtxt('listatodos.txt')\n",
    "stdout = proc.communicate()[0]\n",
    "stdout.replace(\"\\n\",\" \")pyum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creo que esto sobra\n",
    "# Contamos cuantas variables fueron medidas por estacion, se almacena en tomados (cuyo indice coincide con el indice de listam)\n",
    "# PARA LAS QUE TIENEN FILTRO DE ALTURA > 1500 MSNM\n",
    "df=pd.read_csv('lluvia.csv')\n",
    "tomados=np.zeros(len(listam[:,1]))\n",
    "#tomadoscu=np.zeros((len(listam[:,1]),4))\n",
    "for i in range(len(listam[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam[i,1]==df.CODIGO[k]):\n",
    "            tomados[i]+=1           \n",
    "df=pd.read_csv('diaslluvia.csv')\n",
    "for i in range(len(listam[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam[i,1]==df.CODIGO[k]):\n",
    "            tomados[i]+=1  \n",
    "df=pd.read_csv('humedad.csv')\n",
    "for i in range(len(listam[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam[i,1]==df.CODIGO[k]):\n",
    "            tomados[i]+=1\n",
    "df=pd.read_csv('brillo.csv')\n",
    "for i in range(len(listam[:,1])):\n",
    "    for k in range(len(df.CODIGO)):\n",
    "        if(listam[i,1]==df.CODIGO[k]):\n",
    "            tomados[i]+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#probabilidad inversa, qué tan probable es cumplir las cuatro condiciones?\n",
    "\n",
    "for k in range(numtipe):\n",
    "    paparece=1.\n",
    "    filter=(tipoest==k)\n",
    "    myrange=np.arange(tomadoscu.shape[1])[tomadoscu[filter][0]==1]\n",
    "    for j in myrange:\n",
    "        paparece*=(cumple[:,j+1]==1).sum()/2046.\n",
    "    print k,paparece\n",
    "    pClAnTiI[k]=paparece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probtipo=np.zeros(len(listacorta))\n",
    "listacortatipo=np.zeros(len(listacorta))\n",
    "for i in range(len(listacorta)):\n",
    "    for k in range(len(tipoest)):\n",
    "        if(listacorta[i,1]==EST[k,1]):\n",
    "            probtipo[i]=ptipoe[(tipoest[k]).astype(int)]\n",
    "            listacortatipo[i]=tipoest[k]\n",
    "#            print i,k,tipoest[k],ptipoe[tipoest[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pesos estadísticos normalizados considerando distribución de alturas para no. de medidas y no. de criterios\n",
    "aprob=np.vstack((ap1,ap2,ap3,ap4)).T\n",
    "x = np.linspace(0,4500 , 4501)\n",
    "normalt=1/aprob.max()/100\n",
    "probarr=np.zeros(len(probarr3))\n",
    "for i in range(len(probarr3)):\n",
    "    pdf=aprob[:,listacorta[i,0].astype(int)-1]\n",
    "    probarr[i]=probarr3[i]*165*16*np.around(1/pdf/normalt,0)[x==listacorta[i,4]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# la probabilidad\n",
    "# de que cumpla los otros tres criterios se calcula independientemente para cada criterio, es decir\n",
    "# 1036 estaciones cumplieron D, 187 cumplieron H, 227 cumplieron B\n",
    "# P(C|AnT0)=(1036/2046)*(183/2046)*(227/2046)\n",
    "pClAnTiD=np.zeros(numtipe)\n",
    "for k in range(numtipe):\n",
    "    filter=(tipoest==k)\n",
    "    paparece=1.\n",
    "    myrange=np.arange(tomadoscu.shape[1])[np.abs(tomadoscu[filter]-1)[0]==1]\n",
    "    for j in myrange:\n",
    "        paparece*=(cumple[:,j+1]==1).sum()*1./len(EST)\n",
    "    pClAnTiD[k]=paparece    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medidas=tomadoscu.sum(axis=0)\n",
    "pTiI=np.zeros(numtipe)\n",
    "for k in range(numtipe):\n",
    "    filter=(tipoest==k)\n",
    "# probabilidad de tener el tipo de estación (independiente)\n",
    "# probabilidad de medir cada variable por aparte P(Ti)=P(MD)*P(MH)*P(MD)\n",
    "    pTiI[k]=np.prod((medidas*tomadoscu[filter][0]+(len(EST)-medidas)*np.abs(tomadoscu[filter][0]-1))/len(EST))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "Xbic=XprojL\n",
    "bicold=0\n",
    "compo=15\n",
    "BIC=np.zeros((compo+1,4))\n",
    "kik=0\n",
    "for cv_type in cv_types:\n",
    "    for kcomp in np.arange(compo)+1:        \n",
    "        gmm = GMM(kcomp, covariance_type=cv_type, random_state=0)\n",
    "        gmm.fit(Xbic)\n",
    "#        if bicold<gmm.bic(listaexp12[:,2:5]):\n",
    "#        print cv_type,kcomp,gmm.bic(Xbic);\n",
    "        BIC[kcomp,kik]=gmm.bic(Xbic)\n",
    "        bicold=gmm.bic(Xbic)\n",
    "    kik+=1    \n",
    "compx=np.arange(compo+1)[1:]\n",
    "BIC=BIC[1:]\n",
    "for i, cv_type in zip(range(4),cv_types):\n",
    "    plt.plot(compx,BIC[:,i],label=cv_type)\n",
    "plt.legend()\n",
    "plt.xlim(1,compo)\n",
    "plt.xlabel(\"No. of Components\")\n",
    "plt.ylabel(\"BIC\")\n",
    "minperm=np.argmin(BIC,axis=0)\n",
    "bicsmin=np.array([])\n",
    "for i in range(len(minperm)):\n",
    "    bicsmin=np.append(bicsmin,BIC[minperm[i],i])\n",
    "covt=cv_types[np.argmin(bicsmin)]\n",
    "kcomp=minperm[np.argmin(bicsmin)]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para humedad, el PCA cubre >95% de varianza\n",
    "df=pd.read_csv('humedad.csv')\n",
    "\n",
    "AH=df.as_matrix(columns=df.columns[8:20])\n",
    "pca = PCA(0.95)  \n",
    "XprojH = pca.fit_transform(AH)\n",
    "print \"No. of stations that measure this variable = \",XprojH.shape[0],\", No. of PCA components (95%) = \",XprojH.shape[1]\n",
    "print \"Explained variance ratio = \", pca.explained_variance_ratio_.sum(axis=0)\n",
    "print \"Explained variance ratio per component = \", pca.explained_variance_ratio_\n",
    "\n",
    "# para que las gráficas se vean con los mismos ejes\n",
    "xmin=min(XprojH[:, 0])\n",
    "xmax=max(XprojH[:, 0])\n",
    "ymin=min(XprojH[:, 1])\n",
    "ymax=max(XprojH[:, 1])\n",
    "\n",
    "# conversión de formato LATLON\n",
    "latH=np.zeros(len(df.LATITUD))\n",
    "lonH=np.zeros(len(df.LATITUD))\n",
    "codeH=np.zeros(len(df.LATITUD))\n",
    "altH=np.zeros(len(df.LATITUD))\n",
    "for i in range(len(df.LATITUD)):\n",
    "    latH[i]=conversion(df.LATITUD[i])\n",
    "    lonH[i]=conversion(df.LONGITUD[i])\n",
    "    codeH[i]=df.CODIGO[i]\n",
    "    altH[i]=df.ELEV[i]\n",
    "    \n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "Xbic=XprojH\n",
    "bicold=0\n",
    "compo=15\n",
    "BIC=np.zeros((compo+1,4))\n",
    "kik=0\n",
    "for cv_type in cv_types:\n",
    "    for kcomp in np.arange(compo)+1:        \n",
    "        gmm = GMM(kcomp, covariance_type=cv_type, random_state=0)\n",
    "        gmm.fit(Xbic)\n",
    "        BIC[kcomp,kik]=gmm.bic(Xbic)\n",
    "        bicold=gmm.bic(Xbic)\n",
    "    kik+=1    \n",
    "compx=np.arange(compo+1)[1:]\n",
    "BIC=BIC[1:]\n",
    "for i, cv_type in zip(range(4),cv_types):\n",
    "    plt.plot(compx,BIC[:,i],label=cv_type)\n",
    "plt.legend()\n",
    "plt.xlim(1,compo)\n",
    "plt.xlabel(\"No. of Components\")\n",
    "plt.ylabel(\"BIC\")\n",
    "minperm=np.argmin(BIC,axis=0)\n",
    "bicsmin=np.array([])\n",
    "for i in range(len(minperm)):\n",
    "    bicsmin=np.append(bicsmin,BIC[minperm[i],i])\n",
    "covt=cv_types[np.argmin(bicsmin)]\n",
    "kcomp=minperm[np.argmin(bicsmin)]+1\n",
    "    \n",
    "    \n",
    "# Mixtura gaussiana para kcomp clusters\n",
    "#kcomp=2\n",
    "gmm = GMM(kcomp, covariance_type=covt, random_state=0)\n",
    "gmm.fit(XprojH)\n",
    "cluster_labelH = gmm.predict(XprojH)\n",
    "\n",
    "\n",
    "# Se hace una gráfica para cada cluster\n",
    "for kk in range(kcomp):\n",
    "    D=np.zeros([sum(cluster_labelH==kk),2])\n",
    "    B=np.zeros([sum(cluster_labelH==kk),12])\n",
    "    LAT=np.zeros([sum(cluster_labelH==kk)])\n",
    "    LON=np.zeros([sum(cluster_labelH==kk)])\n",
    "    ALTH=np.zeros([sum(cluster_labelH==kk)])\n",
    "    i=0\n",
    "    for k in range(len(cluster_labelH)):\n",
    "        if cluster_labelH[k]==kk:\n",
    "            B[i]=AH[k]\n",
    "            D[i]=XprojH[k]\n",
    "            LAT[i]=latH[k]\n",
    "            LON[i]=lonH[k]\n",
    "            ALTH[i]=df.ELEV[k]\n",
    "            i=i+1\n",
    "    print \"Number of stations in cluster %i is %i\" %(kk,i)\n",
    "    plt.figure(figsize=(20,5*kcomp))\n",
    "    ii=0\n",
    "\n",
    "#\n",
    "    plt.subplot(kcomp, 3, ii+1)\n",
    "    plt.scatter(D[:, 0], D[:, 1],c=ALTH,cmap='cubehelix')\n",
    "    plt.xlim([xmin,xmax])\n",
    "    plt.ylim([ymin,ymax])\n",
    "    plt.xlabel('Comp1')\n",
    "    plt.ylabel('Comp2')\n",
    "\n",
    "    xx=np.arange(12)\n",
    "    plt.subplot(kcomp, 3, ii+2)\n",
    "    plt.plot(B.mean(axis=0))\n",
    "    plt.errorbar(xx,B.mean(axis=0),yerr=B.std(axis=0))\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Rel. Humid.')\n",
    "\n",
    "    plt.subplot(kcomp, 3, ii+3)\n",
    "    plt.scatter(-LON,-LAT,c=ALTH,cmap='cubehelix')\n",
    "    plt.colorbar(label='Altitude, Mean Alt.=%i' % ALTH.mean())\n",
    "    plt.scatter(colvec[:,0],colvec[:,1],s=0.01)\n",
    "    plt.xlim(-85,-65)\n",
    "    plt.ylim(-5,14)\n",
    "    ii=ii+3\n",
    "\n",
    "# Esto es para graficarlos todos en una misma gráfica de LATLON. Ahora LAT y LON son arrays\n",
    "LATH=np.zeros([len(cluster_labelH),kcomp])\n",
    "LONH=np.zeros([len(cluster_labelH),kcomp])\n",
    "ALTH=np.zeros([len(cluster_labelH),kcomp])\n",
    "CODH=np.zeros([len(cluster_labelH),kcomp])\n",
    "for kk in range(kcomp):\n",
    "    i=0\n",
    "    for k in range(len(df)):\n",
    "        if cluster_labelH[k]==kk:\n",
    "            LATH[i,kk]=latH[k]\n",
    "            LONH[i,kk]=lonH[k]\n",
    "            ALTH[i,kk]=df.ELEV[k]\n",
    "            CODH[i,kk]=df.CODIGO[k]\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ahora con lluvia, se requieren 3 componentes para cubrir >95% de varianza\n",
    "df=pd.read_csv('lluvia.csv')\n",
    "df.head()\n",
    "\n",
    "# script que hace todo lo anterior, pero con lluvia, usando lluvia.csv\n",
    "\n",
    "# Componentes principales\n",
    "AL=df.as_matrix(columns=df.columns[8:20])\n",
    "pca = PCA(0.95)  \n",
    "XprojL = pca.fit_transform(AL)\n",
    "print(AL.shape)\n",
    "print(XprojL.shape)\n",
    "print pca.explained_variance_ratio_.sum(axis=0)\n",
    "print pca.explained_variance_ratio_\n",
    "Ncomp = XprojL.shape[1]\n",
    "\n",
    "# para que las gráficas se vean con los mismos ejes\n",
    "xmin=min(XprojL[:, 0])\n",
    "xmax=max(XprojL[:, 0])\n",
    "ymin=min(XprojL[:, 1])\n",
    "ymax=max(XprojL[:, 1])\n",
    "\n",
    "# conversión de formato LATLON\n",
    "latL=np.zeros(len(df.LATITUD))\n",
    "lonL=np.zeros(len(df.LATITUD))\n",
    "codeL=np.zeros(len(df.LATITUD))\n",
    "altL=np.zeros(len(df.LATITUD))\n",
    "for i in range(len(df.LATITUD)):\n",
    "    latL[i]=conversion(df.LATITUD[i])\n",
    "    lonL[i]=conversion(df.LONGITUD[i])\n",
    "    codeL[i]=df.CODIGO[i]\n",
    "    altL[i]=df.ELEV[i]\n",
    "    \n",
    "# Mixtura gaussiana para kcomp clusters (4)\n",
    "kcomp=11\n",
    "gmm = GMM(kcomp, covariance_type='full', random_state=0)\n",
    "gmm.fit(XprojL)\n",
    "cluster_labelL = gmm.predict(XprojL)\n",
    "\n",
    "\n",
    "# Se hace una gráfica para cada cluster\n",
    "for kk in range(kcomp):\n",
    "    D=np.zeros([sum(cluster_labelL==kk),Ncomp])\n",
    "    B=np.zeros([sum(cluster_labelL==kk),12])\n",
    "    LAT=np.zeros([sum(cluster_labelL==kk)])\n",
    "    LON=np.zeros([sum(cluster_labelL==kk)])\n",
    "    ALTL=np.zeros([sum(cluster_labelL==kk)])\n",
    "    i=0\n",
    "    for k in range(len(df)):\n",
    "        if cluster_labelL[k]==kk:\n",
    "            B[i]=AL[k]\n",
    "            D[i]=XprojL[k]\n",
    "            LAT[i]=latL[k]\n",
    "            LON[i]=lonL[k]\n",
    "            ALTL[i]=df.ELEV[k]\n",
    "            i=i+1\n",
    "    print \"Number of stations in cluster %i is %i\" %(kk,i)\n",
    "    plt.figure(figsize=(20,5*kcomp))\n",
    "    ii=0\n",
    "\n",
    "#\n",
    "    plt.subplot(kcomp, 3, ii+1)\n",
    "    plt.scatter(D[:, 0], D[:, 1],c=ALTL,cmap='cubehelix')\n",
    "    plt.xlim([xmin,xmax])\n",
    "    plt.ylim([ymin,ymax])\n",
    "    plt.xlabel('Comp1')\n",
    "    plt.ylabel('Comp2')\n",
    "\n",
    "    xx=np.arange(12)\n",
    "    plt.subplot(kcomp, 3, ii+2)\n",
    "    plt.plot(B.mean(axis=0))\n",
    "    plt.errorbar(xx,B.mean(axis=0),yerr=B.std(axis=0))\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Precip., Av. =%5.f' % B.mean(axis=0).sum())\n",
    "\n",
    "    plt.subplot(kcomp, 3, ii+3)\n",
    "    plt.scatter(-LON,-LAT,c=ALTL,cmap='cubehelix')\n",
    "    plt.colorbar(label='Altitude, Mean Alt.=%i' % ALTL.mean())\n",
    "    plt.scatter(colvec[:,0],colvec[:,1],s=0.01)\n",
    "    plt.xlim(-85,-65)\n",
    "    plt.ylim(-5,14)\n",
    "    ii=ii+3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Esto es para graficarlos todos en una misma gráfica de LATLON. Ahora LAT y LON son arrays\n",
    "LATL=np.zeros([len(cluster_labelL),kcomp])\n",
    "LONL=np.zeros([len(cluster_labelL),kcomp])\n",
    "ALTL=np.zeros([len(cluster_labelL),kcomp])\n",
    "CODL=np.zeros([len(cluster_labelL),kcomp])\n",
    "for kk in range(kcomp):\n",
    "    i=0\n",
    "    for k in range(len(df)):\n",
    "        if cluster_labelL[k]==kk:\n",
    "            LATL[i,kk]=latL[k]\n",
    "            LONL[i,kk]=lonL[k]\n",
    "            ALTL[i,kk]=df.ELEV[k]\n",
    "            CODL[i,kk]=df.CODIGO[k]\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ahora con días con lluvia, también toca con tres componentes\n",
    "df=pd.read_csv('diaslluvia.csv')\n",
    "\n",
    "#datos crudos mes a mes por estacion - días con lluvia de diaslluvia.csv\n",
    "#AB=AD[np.isfinite(AD).prod(axis=1).astype(bool),:]\n",
    "AD=df.as_matrix(columns=df.columns[8:20])\n",
    "pca = PCA(0.95)  \n",
    "XprojD = pca.fit_transform(AD)\n",
    "print(AD.shape)\n",
    "print(XprojD.shape)\n",
    "print pca.explained_variance_ratio_.sum(axis=0)\n",
    "print pca.explained_variance_ratio_\n",
    "Ncomp = XprojD.shape[1]\n",
    "\n",
    "# para que las gráficas se vean con los mismos ejes\n",
    "xmin=min(XprojD[:, 0])\n",
    "xmax=max(XprojD[:, 0])\n",
    "ymin=min(XprojD[:, 1])\n",
    "ymax=max(XprojD[:, 1])\n",
    "\n",
    "# conversión de formato LATLON\n",
    "latD=np.zeros(len(df.LATITUD))\n",
    "lonD=np.zeros(len(df.LATITUD))\n",
    "codeD=np.zeros(len(df.LATITUD))\n",
    "altD=np.zeros(len(df.LATITUD))\n",
    "for i in range(len(df.LATITUD)):\n",
    "    latD[i]=conversion(df.LATITUD[i])\n",
    "    lonD[i]=conversion(df.LONGITUD[i])\n",
    "    codeD[i]=df.CODIGO[i]    \n",
    "    altD[i]=df.ELEV[i]\n",
    "# Mixtura gaussiana para kcomp clusters\n",
    "kcomp=6\n",
    "gmm = GMM(kcomp, covariance_type='full', random_state=0)\n",
    "gmm.fit(XprojD)\n",
    "cluster_labelD = gmm.predict(XprojD)\n",
    "#df['Cluster1'] = cluster_label\n",
    "\n",
    "# Se hace una gráfica para cada cluster\n",
    "for kk in range(kcomp):\n",
    "    D=np.zeros([sum(cluster_labelD==kk),Ncomp])\n",
    "    B=np.zeros([sum(cluster_labelD==kk),12])\n",
    "    LAT=np.zeros([sum(cluster_labelD==kk)])\n",
    "    LON=np.zeros([sum(cluster_labelD==kk)])\n",
    "    ALT=np.zeros([sum(cluster_labelD==kk)])\n",
    "    i=0\n",
    "    for k in range(len(cluster_labelD)):\n",
    "        if cluster_labelD[k]==kk:\n",
    "            B[i]=AD[k]\n",
    "            D[i]=XprojD[k]\n",
    "            LAT[i]=latD[k]\n",
    "            LON[i]=lonD[k]\n",
    "            ALT[i]=df.ELEV[k]\n",
    "            i=i+1\n",
    "    print \"Number of stations in cluster %i is %i\" %(kk,i)\n",
    "    plt.figure(figsize=(20,5*kcomp))\n",
    "    ii=0\n",
    "\n",
    "#\n",
    "    plt.subplot(kcomp, 3, ii+1)\n",
    "    plt.scatter(D[:, 0], D[:, 1],c=ALT,cmap='cubehelix')\n",
    "    plt.xlim([xmin,xmax])\n",
    "    plt.ylim([ymin,ymax])\n",
    "    plt.xlabel('Comp1')\n",
    "    plt.ylabel('Comp2')\n",
    "\n",
    "    xx=np.arange(12)\n",
    "    plt.subplot(kcomp, 3, ii+2)\n",
    "    plt.plot(B.mean(axis=0))\n",
    "    plt.errorbar(xx,B.mean(axis=0),yerr=B.std(axis=0))\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Rainy days, Av. =%5.f, Std. =%2.2f' % (B.mean(axis=0).mean(),B.std(axis=0).mean())  )\n",
    "\n",
    "    plt.subplot(kcomp, 3, ii+3)\n",
    "    plt.scatter(-LON,-LAT,c=ALT,cmap='cubehelix')\n",
    "    plt.colorbar(label='Altitude, Mean Alt.=%i' % ALT.mean())\n",
    "    plt.scatter(colvec[:,0],colvec[:,1],s=0.01)\n",
    "    plt.xlim(-85,-65)\n",
    "    plt.ylim(-5,14)\n",
    "    ii=ii+3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Esto es para graficarlos todos en una misma gráfica de LATLON. Ahora LAT y LON son arrays\n",
    "LATD=np.zeros([len(cluster_labelD),kcomp])\n",
    "LOND=np.zeros([len(cluster_labelD),kcomp])\n",
    "ALTD=np.zeros([len(cluster_labelD),kcomp])\n",
    "CODD=np.zeros([len(cluster_labelD),kcomp])\n",
    "\n",
    "for kk in range(kcomp):\n",
    "    i=0\n",
    "    for k in range(len(cluster_labelD)):\n",
    "        if cluster_labelD[k]==kk:\n",
    "            LATD[i,kk]=latD[k]\n",
    "            LOND[i,kk]=lonD[k]\n",
    "            ALTD[i,kk]=df.ELEV[k]\n",
    "            CODD[i,kk]=df.CODIGO[k]\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ahora con brillo solar\n",
    "df=pd.read_csv('brillo.csv')\n",
    "\n",
    "#datos crudos mes a mes por estacion - brillo solar de brillo.csv\n",
    "AB=df.as_matrix(columns=df.columns[8:20])\n",
    "pca = PCA(0.95)  \n",
    "XprojB = pca.fit_transform(AB)\n",
    "print(AB.shape)\n",
    "print(XprojB.shape)\n",
    "print pca.explained_variance_ratio_.sum(axis=0)\n",
    "print pca.explained_variance_ratio_\n",
    "Ncomp = XprojB.shape[1]\n",
    "\n",
    "\n",
    "# para que las gráficas se vean con los mismos ejes\n",
    "xmin=min(XprojB[:, 0])\n",
    "xmax=max(XprojB[:, 0])\n",
    "ymin=min(XprojB[:, 1])\n",
    "ymax=max(XprojB[:, 1])\n",
    "\n",
    "# conversión de formato LATLON\n",
    "latB=np.zeros(len(df.LATITUD))\n",
    "lonB=np.zeros(len(df.LATITUD))\n",
    "codeB=np.zeros(len(df.LATITUD))\n",
    "altB=np.zeros(len(df.LATITUD))\n",
    "for i in range(len(df.LATITUD)):\n",
    "    latB[i]=conversion(df.LATITUD[i])\n",
    "    lonB[i]=conversion(df.LONGITUD[i])\n",
    "    codeB[i]=df.CODIGO[i]    \n",
    "    altB[i]=df.ELEV[i]\n",
    "# Mixtura gaussiana para kcomp clusters\n",
    "kcomp=5\n",
    "gmm = GMM(kcomp, covariance_type='tied', random_state=0)\n",
    "gmm.fit(XprojB)\n",
    "print gmm.bic(XprojB)\n",
    "cluster_labelB = gmm.predict(XprojB)\n",
    "\n",
    "# Se hace una gráfica para cada cluster\n",
    "for kk in range(kcomp):\n",
    "    D=np.zeros([sum(cluster_labelB==kk),Ncomp])\n",
    "    B=np.zeros([sum(cluster_labelB==kk),12])\n",
    "    LAT=np.zeros([sum(cluster_labelB==kk)])\n",
    "    LON=np.zeros([sum(cluster_labelB==kk)])\n",
    "    ALT=np.zeros([sum(cluster_labelB==kk)])\n",
    "    i=0\n",
    "    for k in range(len(cluster_labelB)):\n",
    "        if cluster_labelB[k]==kk:\n",
    "            B[i]=AB[k]\n",
    "            D[i]=XprojB[k]\n",
    "            LAT[i]=latB[k]\n",
    "            LON[i]=lonB[k]\n",
    "            ALT[i]=df.ELEV[k]\n",
    "            i=i+1\n",
    "    print \"Number of stations in cluster %i is %i\" %(kk,i)\n",
    "    plt.figure(figsize=(20,5*kcomp))\n",
    "    ii=0\n",
    "\n",
    "#\n",
    "    plt.subplot(kcomp, 3, ii+1)\n",
    "    plt.scatter(D[:, 0], D[:, 1],c=ALT,cmap='cubehelix')\n",
    "    plt.xlim([xmin,xmax])\n",
    "    plt.ylim([ymin,ymax])\n",
    "    plt.xlabel('Comp1')\n",
    "    plt.ylabel('Comp2')\n",
    "\n",
    "    xx=np.arange(12)\n",
    "    plt.subplot(kcomp, 3, ii+2)\n",
    "    plt.plot(B.mean(axis=0))\n",
    "    plt.errorbar(xx,B.mean(axis=0),yerr=B.std(axis=0))\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Sunshine Duration (Daily), Av. =%.2f' % B.mean(axis=0).mean())\n",
    "\n",
    "    plt.subplot(kcomp, 3, ii+3)\n",
    "    plt.scatter(-LON,-LAT,c=ALT,cmap='cubehelix')\n",
    "    plt.colorbar(label='Altitude, Mean Alt.=%i' % ALT.mean())\n",
    "    plt.scatter(colvec[:,0],colvec[:,1],s=0.01)\n",
    "    plt.xlim(-85,-65)\n",
    "    plt.ylim(-5,14)\n",
    "    ii=ii+3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Esto es para graficarlos todos en una misma gráfica de LATLON. Ahora LAT y LON son arrays\n",
    "LATB=np.zeros([len(cluster_labelB),kcomp])\n",
    "LONB=np.zeros([len(cluster_labelB),kcomp])\n",
    "ALTB=np.zeros([len(cluster_labelB),kcomp])\n",
    "CODB=np.zeros([len(cluster_labelB),kcomp])\n",
    "for kk in range(kcomp):\n",
    "    i=0\n",
    "    for k in range(len(cluster_labelB)):\n",
    "        if cluster_labelB[k]==kk:\n",
    "            LATB[i,kk]=latB[k]\n",
    "            LONB[i,kk]=lonB[k]\n",
    "            ALTB[i,kk]=df.ELEV[k]\n",
    "            CODB[i,kk]=df.CODIGO[k]\n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candfilter=cumple.sum(axis=1)!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Jake VanderPlas\n",
    "# License: BSD\n",
    "#----------------------------------------------------------------------\n",
    "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
    "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
    "# result in an error if LaTeX is not installed on your system.  In that case,\n",
    "# you can set usetex to False.\n",
    "def altprob(alt,filter):\n",
    "    altmax=EST[:,4].max().astype(int)\n",
    "    from astroML.plotting import setup_text_plots\n",
    "    setup_text_plots(fontsize=12, usetex=True)\n",
    "    altmin=0\n",
    "    X = alt[filter][:, np.newaxis]\n",
    "    #------------------------------------------------------------\n",
    "    # Learn the best-fit GMM models\n",
    "    #  Here we'll use GMM in the standard way: the fit() method\n",
    "    #  uses an Expectation-Maximization approach to find the best\n",
    "    #  mixture of Gaussians for the data\n",
    "    # fit models with 1-11 components\n",
    "    nmax=np.min([len(alt[filter]),15])\n",
    "    N = np.arange(1, nmax)\n",
    "    models = [None for i in range(len(N))]\n",
    "\n",
    "    for i in range(len(N)):\n",
    "        models[i] = GMM(N[i]).fit(X)\n",
    "\n",
    "    # compute the AIC and the BIC\n",
    "    AIC = [m.aic(X) for m in models]\n",
    "    BIC = [m.bic(X) for m in models]\n",
    "\n",
    "    #------------------------------------------------------------\n",
    "    # Plot the results\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    fig.subplots_adjust(left=0.12, right=0.97,\n",
    "                        bottom=0.21, top=0.9, wspace=0.5)\n",
    "\n",
    "\n",
    "    # plot 1: data + best-fit mixture\n",
    "    ax = fig.add_subplot(121)\n",
    "    M_best = models[np.argmin(AIC)]\n",
    "\n",
    "    x = np.linspace(altmin,altmax-2, altmax-1)\n",
    "    logprob, responsibilities = M_best.score_samples(x.reshape((-1,1)))\n",
    "    pdf = np.exp(logprob)\n",
    "    pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "\n",
    "\n",
    "    ax.hist(X, normed=True, histtype='stepfilled', alpha=0.4,bins=range(0,4500,50))\n",
    "    ax.plot(x, pdf, '-k')\n",
    "    ax.plot(x, pdf_individual, '--k')\n",
    "    ax.text(0.04, 0.96, \"Best-fit Mixture\",\n",
    "            ha='left', va='top', transform=ax.transAxes)\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$p(x)$')\n",
    "    ax.set_xlim([0,4500])\n",
    "    ax.set_ylim([0,0.0016])\n",
    "\n",
    "    # plot 2: AIC and BIC\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(N, AIC, '-k', label='AIC')\n",
    "    ax.plot(N, BIC, '--k', label='BIC')\n",
    "    ax.set_xlabel('n. components')\n",
    "    ax.set_ylabel('information criterion')\n",
    "    ax.legend(loc=2)\n",
    "    plt.show()\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Si queremos P(h|T0,1) continuas, si no ignorar\n",
    "proh[:,0]=altprob(listam[:,4],listam[:,0]==0)\n",
    "proh[:,1]=altprob(listam[:,4],listam[:,0]==1)\n",
    "# Si queremos P(h) continua, si no ignorar\n",
    "filter=np.isfinite(EST[:,4])\n",
    "prohabs=altprob(EST[:,4],filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "filter=(listcomp[:,7]==0)\n",
    "plt.scatter(-listcomp[:,3][filter],-listcomp[:,4][filter],c='k',s=listcomp[:,0][filter])\n",
    "filter=(listcomp[:,7]==1)\n",
    "plt.scatter(-listcomp[:,3][filter],-listcomp[:,4][filter],c='r',s=listcomp[:,0][filter])\n",
    "filter=(listcomp[:,7]==2)\n",
    "plt.scatter(-listcomp[:,3][filter],-listcomp[:,4][filter],c='b',s=listcomp[:,0][filter])\n",
    "filter=(listcomp[:,7]==3)\n",
    "plt.scatter(-listcomp[:,3][filter],-listcomp[:,4][filter],c='y',s=listcomp[:,0][filter])\n",
    "filter=(listcomp[:,7]==4)\n",
    "plt.scatter(-listcomp[:,3][filter],-listcomp[:,4][filter],c='g',s=listcomp[:,0][filter])\n",
    "filter=(listcomp[:,7]==5)\n",
    "plt.scatter(-listcomp[:,3][filter],-listcomp[:,4][filter],c='c',s=listcomp[:,0][filter])\n",
    "filter=(listcomp[:,7]==6)\n",
    "plt.scatter(-listcomp[:,3][filter],-listcomp[:,4][filter],c='m',s=listcomp[:,0][filter])\n",
    "plt.scatter(colvec[:,0],colvec[:,1],s=1)\n",
    "plt.scatter(np.array([-73.06]),np.array([6.3211484]),s=100,c='c')\n",
    "#plt.colorbar()\n",
    "plt.xlim(-80,-70)\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=0\n",
    "x=EST[critfilter][tipoest[critfilter]==k][:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def kde_sklearn(x, x_grid, bandwidth=0.2, **kwargs):\n",
    "    \"\"\"Kernel Density Estimation with Scikit-learn\"\"\"\n",
    "    kde_skl = KernelDensity(bandwidth=bandwidth, **kwargs)\n",
    "    kde_skl.fit(x[:, np.newaxis])\n",
    "    # score_samples() returns the log-likelihood of the samples\n",
    "    log_pdf = kde_skl.score_samples(x_grid[:, np.newaxis])\n",
    "    return np.exp(log_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=1\n",
    "x=EST[critfilter][tipoest[critfilter]==k][:,4]\n",
    "x_grid=np.around(np.arange(x.min(),x.max(),1),2)\n",
    "fig, ax = plt.subplots()\n",
    "for bandwidth in [ 1, 200, 500]:\n",
    "    ax.plot(x_grid, kde_sklearn(x, x_grid, bandwidth=bandwidth),\n",
    "            label='bw={0}'.format(bandwidth), linewidth=3)\n",
    "ax.hist(x, 50, fc='gray', histtype='stepfilled', alpha=0.3, normed=True)\n",
    "ax.set_xlim(x.min(), x.max())\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(KernelDensity(),\n",
    "                    {'bandwidth': np.linspace(1, 100, 10)},\n",
    "                    cv=13) # 20-fold cross-validation\n",
    "grid.fit(x[:, None])\n",
    "print grid.best_params_\n",
    "kde = grid.best_estimator_\n",
    "pdf = np.exp(kde.score_samples(x_grid[:, None]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_grid, pdf, linewidth=3, alpha=0.5, label='bw=%.2f' % kde.bandwidth)\n",
    "ax.hist(x, 30, fc='gray', histtype='stepfilled', alpha=0.3, normed=True)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlim(x.min(), x.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
